{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIs9bQbFz90M"
      },
      "source": [
        "## Importação do [dataset do Kaggle](https://www.kaggle.com/datasets/steubk/wikiart)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "YCvAIdzA02Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# num_classes = len(train_data.class_names)\n",
        "\n",
        "# VERSÃO 3\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(220, 220, 3)),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomBrightness(0.2),\n",
        "  layers.RandomContrast(0.2),\n",
        "  ]\n",
        ")\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(5, name=\"outputs\", activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "n1epMy4t02rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights from file model\n",
        "model.load_weights('model_5_classes.weights.h5')"
      ],
      "metadata": {
        "id": "0YqxJKXr3phc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phimu1lX_GeL"
      },
      "outputs": [],
      "source": [
        "# instalação da lib do Kaggle (kagglehub) para realizar download\n",
        "# !pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvO75LcDEoVf"
      },
      "outputs": [],
      "source": [
        "# imports utilizados no código\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv_s3P93_GY-"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"steubk/wikiart\")\n",
        "print(\"Path to dataset files:\", path) # Path to dataset files: /root/.cache/kagglehub/datasets/steubk/wikiart/versions/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTIKFJD4BczI"
      },
      "outputs": [],
      "source": [
        "# classes.csv\n",
        "path = '/root/.cache/kagglehub/datasets/steubk/wikiart/versions/1/'\n",
        "dataset_path = os.path.join(path, 'classes.csv')\n",
        "df = pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv3uDwPoz2fq"
      },
      "source": [
        "## Exploração do dataset, suas colunas e informações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umRrVGgmY4ri"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqaKjjRIZHLT"
      },
      "outputs": [],
      "source": [
        "df.info(), df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spldbbbbaPFC"
      },
      "outputs": [],
      "source": [
        "df['subset'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOmM7CpwasvG"
      },
      "outputs": [],
      "source": [
        "df['artist'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMJXNJbMavoe"
      },
      "outputs": [],
      "source": [
        "# df['genre'].value_counts().tail(25)\n",
        "df['genre'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWb9o6ljGUA2"
      },
      "outputs": [],
      "source": [
        "# # para reconhecer que há mais de uma classificação na instância: apresentar caractere vírgula\n",
        "\n",
        "# # verifica presença de vírgula para cada instância do df\n",
        "# result = df['genre'].apply(lambda x: ',' in x)\n",
        "# # inverte os resultados (quando há vírgula, temos False; quando não há vírgula, temos True)\n",
        "# df = df[~result] # novo df apresenta instâncias com uma classificação apenas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfJrl8_6PcS7"
      },
      "source": [
        "## Preparação do Dataset\n",
        "\n",
        "A distribuição das classes está desbalanceada. Para não gerar overfitting no modelo, vamos equilibrar as quantidades de instâncias das classes.\n",
        "\n",
        "Uso de Augmentation Transforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcEPZnpjPuac"
      },
      "outputs": [],
      "source": [
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# separação do dataset para treinamento e teste\n",
        "df_train = df[df['subset'] == 'train']\n",
        "df_test = df[df['subset'] == 'test']\n",
        "\n",
        "count_values = df_train['genre'].value_counts()\n",
        "keys = []\n",
        "values = []\n",
        "\n",
        "# chaves e valores guardados em listas\n",
        "for key, value in count_values.items():\n",
        "  keys.append(key)\n",
        "  values.append(value)\n",
        "\n",
        "# visualizando graficamente\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "# nomes das classes no eixo x; quantidades das instâncias dessas classes no eixo y\n",
        "ax.bar(keys, values)\n",
        "# configura rotação dos nomes para melhorar legibilidade\n",
        "plt.xticks(rotation=50, ha='right')\n",
        "plt.show() # exibe\n",
        "\n",
        "# quantidades de instâncias das classes muito diferentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oYtU2rNanmN"
      },
      "source": [
        "## Usando Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHpa_DpzZ7pi"
      },
      "outputs": [],
      "source": [
        "# importação das bibliotecas do Keras e TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gYDir2N1iPe"
      },
      "source": [
        "### Dataset a partir dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0HtsfSXEXi7"
      },
      "source": [
        "#### Exclusão de instâncias com mais de uma classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGLklMXGDLR5"
      },
      "outputs": [],
      "source": [
        "# vamos retirar algumas das classes que apresentam poucas instâncias de dados\n",
        "# Fauvism, Pointillism, Contemporary Realism, New Realism, Synthetic Cubism, Analytical Cubism, Action painting\n",
        "\n",
        "# a retirada das classes é feita antes da captura do dataset a partir do diretório\n",
        "\n",
        "list_directory = os.listdir(path)\n",
        "print(len(list_directory), list_directory)\n",
        "\n",
        "# essas classes apresentam poucas instâncias, o que inviabiliza a inclusão destas no treinamento do modelo (quantidade de instâncias insuficiente)\n",
        "direc_remove = ['Pointillism', 'Contemporary_Realism', 'New_Realism', 'Synthetic_Cubism', 'Analytical_Cubism', 'Action_painting']\n",
        "\n",
        "# exclusão de outras classes\n",
        "direc_remove = direc_remove + ['Impressionism', 'Realism', 'Romanticism', 'Post_Impressionism', 'Expressionism', 'Symbolism', 'Art_Nouveau_Modern', 'Baroque',\n",
        "                               'Abstract_Expressionism', 'Northern_Renaissance', 'Naive_Art_Primitivism', 'Rococo', 'Cubism', 'Color_Field_Painting', 'High_Renaissance',\n",
        "                               'Mannerism_Late_Renaissance']\n",
        "\n",
        "for folder in direc_remove:\n",
        "  folder_path = os.path.join(path, folder)\n",
        "  try:\n",
        "    if os.path.isdir(folder_path):\n",
        "      shutil.rmtree(folder_path)\n",
        "      print('Removed: ', path + folder, end='. ')\n",
        "  except Exception as e:\n",
        "    print('Error: failed', path + folder, end='. ')\n",
        "\n",
        "list_directory = os.listdir(path)\n",
        "print()\n",
        "print(len(list_directory), list_directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# renaissance = ['Mannerism_Late_Renaissance', 'Early_Renaissance', 'High_Renaissance']\n",
        "# renaissance_dir = path"
      ],
      "metadata": {
        "id": "ODU3gcsXGJ2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh9bMfdJS9Fm"
      },
      "outputs": [],
      "source": [
        "# retirada de imagens com mais de uma classificação\n",
        "# exclusão desses dados é feita no sistema (antes de carregamento dos dados para um dataset)\n",
        "\n",
        "for _, instance in df.iterrows():\n",
        "  file_path = str(instance['filename'])\n",
        "  image_classes = str(instance['genre'])\n",
        "  # print(image_classes.find(','))\n",
        "  # busca uma vírgula na string das classes da pintura\n",
        "  if (image_classes.find(',') != -1):\n",
        "    # encontrou vírgula\n",
        "    file_path = os.path.join(path, file_path)\n",
        "    try:\n",
        "      os.remove(file_path)\n",
        "      print('Removed: ', file_path)\n",
        "    except Exception as e:\n",
        "      print('Error: failed', file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BioVOAwMOlOU"
      },
      "outputs": [],
      "source": [
        "train_data, val_data = keras.utils.image_dataset_from_directory(\n",
        "    path,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(220, 220),\n",
        "    shuffle=True,\n",
        "    seed=49,\n",
        "    validation_split=0.2,\n",
        "    subset='both',\n",
        "    interpolation=\"bilinear\",\n",
        "    data_format=None,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "train_data, val_data, train_data.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLq3a5rGFXzL"
      },
      "outputs": [],
      "source": [
        "# # retirada de imagens que apresentam mais de uma classificação\n",
        "# from tensorflow import reduce_sum\n",
        "\n",
        "# def filter_classes(image, label):\n",
        "#   # classes estão codificadas com one hot encoding\n",
        "#   # assim, conta quantos 1's estão presentes na classificação de uma imagem\n",
        "#   count_classes = reduce_sum(label)\n",
        "#   # verifica se o contador de classes é igual a 1 e retorna True ou False\n",
        "#   return tf.equal(count_classes, 1)\n",
        "\n",
        "# # realiza unbatch do dataset; assim, as imagens são percorridas e o filtro é aplicado individualmente a cada imagem\n",
        "# unbatch_train_data = train_data.unbatch()\n",
        "\n",
        "# # aplica filtro\n",
        "# filtered_train_data = unbatch_train_data.filter(filter_classes)\n",
        "\n",
        "# # retorna ao formato de batches\n",
        "# batch_size = 32\n",
        "# filtered_train_data = filtered_train_data.batch(batch_size)\n",
        "# filtered_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaBoKP4LFS_k"
      },
      "outputs": [],
      "source": [
        "# from collections import defaultdict\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Conta as instâncias por classe\n",
        "# groups = defaultdict(int)\n",
        "\n",
        "# for image, label in train_data:\n",
        "#   # retorna as classes das 32 imagens do batch atual\n",
        "#   classes_images = tf.argmax(label, axis=1).numpy() # transforma o array para um objeto numpy\n",
        "#   # percorre os 32 valores do array (em que cada um representa a classe de uma imagem)\n",
        "#   for one_class in classes_images:\n",
        "#     groups[one_class] += 1 # incrementa o contador para a classe\n",
        "\n",
        "# # verifica qual das classes apresenta menor quantidade de instâncias; salva esse número de instâncias em number_samples\n",
        "# number_samples = min(groups.values())\n",
        "# groups, number_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyy5RBwqFzxb"
      },
      "outputs": [],
      "source": [
        "# grouped_data = defaultdict(list)\n",
        "\n",
        "# for image, label in train_data:\n",
        "#     classes_images = tf.argmax(label, axis=1).numpy()\n",
        "#     for img, cls in zip(image.numpy(), classes_images):\n",
        "#         grouped_data[cls].append(img)\n",
        "\n",
        "# # Realize o downsampling\n",
        "# balanced_images = []\n",
        "# balanced_labels = []\n",
        "\n",
        "# for cls, images in grouped_data.items():\n",
        "#     selected_images = np.random.choice(len(images), number_samples, replace=False)\n",
        "#     for idx in selected_images:\n",
        "#         balanced_images.append(images[idx])\n",
        "#         balanced_labels.append(cls)\n",
        "\n",
        "# num_classes = max(balanced_labels) + 1\n",
        "\n",
        "# # Converta os dados para tensores\n",
        "# balanced_images = tf.convert_to_tensor(balanced_images)\n",
        "# balanced_labels = tf.keras.utils.to_categorical(balanced_labels, num_classes=num_classes)\n",
        "\n",
        "# # Crie um novo dataset com os dados balanceados\n",
        "# balanced_dataset = tf.data.Dataset.from_tensor_slices((balanced_images, balanced_labels))\n",
        "# balanced_dataset, len(balanced_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxEYGO1t4unh"
      },
      "outputs": [],
      "source": [
        "# from collections import defaultdict\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # Conta as instâncias por classe\n",
        "# groups = defaultdict(int)\n",
        "\n",
        "# for image, label in train_data:\n",
        "#   # retorna as classes das 32 imagens do batch atual\n",
        "#   classes_images = tf.argmax(label, axis=1).numpy() # transforma o array para um objeto numpy\n",
        "#   # percorre os 32 valores do array (em que cada um representa a classe de uma imagem)\n",
        "#   for one_class in classes_images:\n",
        "#     groups[one_class] += 1 # incrementa o contador para a classe\n",
        "\n",
        "# # verifica qual das classes apresenta menor quantidade de instâncias; salva esse número de instâncias em number_samples\n",
        "# number_samples = min(groups.values())\n",
        "# groups, number_samples\n",
        "\n",
        "# # defaultdict(int,\n",
        "# # \t\t             {1: 3470,\n",
        "# # \t\t              7: 1082,\n",
        "# # \t\t              6: 5370,\n",
        "# # \t\t              14: 5170,\n",
        "# # \t\t              3: 1307,\n",
        "# # \t\t              17: 5596,\n",
        "# # \t\t              15: 8612,\n",
        "# # \t\t              8: 10484,\n",
        "# # \t\t              18: 3588,\n",
        "# # \t\t              10: 1082,\n",
        "# # \t\t              4: 1783,\n",
        "# # \t\t              5: 1110,\n",
        "# # \t\t              2: 3352,\n",
        "# # \t\t              0: 2238,\n",
        "# # \t\t              9: 1049,\n",
        "# # \t\t              11: 1914,\n",
        "# # \t\t              13: 1183,\n",
        "# # \t\t              12: 2037,\n",
        "# # \t\t              16: 1659,\n",
        "# # \t\t              19: 937}),\n",
        "# # \t\t 937"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWpLSpEpEtug"
      },
      "outputs": [],
      "source": [
        "# # retirada de imagens que apresentam mais de uma classificação\n",
        "# from tensorflow import reduce_sum\n",
        "\n",
        "# def filter_classes(image, label):\n",
        "#   # classes estão codificadas com one hot encoding\n",
        "#   # assim, conta quantos 1's estão presentes na classificação de uma imagem\n",
        "#   count_classes = reduce_sum(label)\n",
        "#   # verifica se o contador de classes é igual a 1 e retorna True ou False\n",
        "#   return tf.equal(count_classes, 1)\n",
        "\n",
        "# # realiza unbatch do dataset; assim, as imagens são percorridas e o filtro é aplicado individualmente a cada imagem\n",
        "# unbatch_train_data = train_data.unbatch()\n",
        "\n",
        "# # aplica filtro\n",
        "# filtered_train_data = unbatch_train_data.filter(filter_classes)\n",
        "\n",
        "# # retorna ao formato de batches\n",
        "# batch_size = 32\n",
        "# filtered_train_data = filtered_train_data.batch(batch_size)\n",
        "# filtered_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnwSSEoyMXws"
      },
      "outputs": [],
      "source": [
        "# os códigos comentados abaixo atingiram limite da memória RAM e não serão utilizados\n",
        "\n",
        "# # criação de arrays para dados de treinamento e validação\n",
        "\n",
        "# num_images = len(df_train)\n",
        "# train_data = np.zeros((num_images, 224, 224, 3), dtype=np.float32)\n",
        "# path = '/root/.cache/kagglehub/datasets/steubk/wikiart/versions/1'\n",
        "\n",
        "# # a partir do filename do dataframe, pegamos o arquivo da imagem, abrimos, fazemos redimensionamento e transformamos em array\n",
        "# for i in range(num_images):\n",
        "#   filename = df_train.iloc[i]['filename']\n",
        "#   try:\n",
        "#     img = tf.keras.preprocessing.image.load_img(path + '/' + filename, target_size=(224, 224))\n",
        "#     train_data[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
        "#   except Exception as e:\n",
        "#     print('Erro - ', path + '/' + filename, e)\n",
        "\n",
        "# train_data[:5]\n",
        "\n",
        "# num_images = len(df_test)\n",
        "# val_data = np.zeros((num_images, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# for i in range(num_images):\n",
        "#   filename = df_test.iloc[i]['filename']\n",
        "#   try:\n",
        "#     img = tf.keras.preprocessing.image.load_img(path + '/' + filename, target_size=(224, 224))\n",
        "#     val_data[i] = tf.keras.preprocessing.image.img_to_array(img)\n",
        "#   except Exception as e:\n",
        "#     print('Erro - ', path + '/' + filename, e)\n",
        "\n",
        "# val_data[:5]\n",
        "\n",
        "# my_dict = df_train['genre'].value_counts().to_dict()\n",
        "\n",
        "# list_classes = []\n",
        "# for i in my_dict.keys():\n",
        "#   string = str(i)\n",
        "#   list_classes.append(string)\n",
        "\n",
        "# # ---\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# label_enc = LabelEncoder()\n",
        "# label_enc.fit(list_classes)\n",
        "# label_enc.transform(list_classes)\n",
        "\n",
        "# train_labels = []\n",
        "\n",
        "# for i in range(len(df_train)):\n",
        "#   label = label_enc.transform([str(df_train['genre'][i])])\n",
        "#   train_labels.append(label)\n",
        "\n",
        "# train_labels\n",
        "\n",
        "# val_labels = []\n",
        "\n",
        "# for i in range(len(df_train)):\n",
        "#   label = label_enc.transform([str(df_train['genre'][i])])\n",
        "#   val_labels.append(label)\n",
        "\n",
        "# val_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYiC6U9bOgQz"
      },
      "source": [
        "## Modelo CNN - Usando Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4Yf0P9hZe3-"
      },
      "outputs": [],
      "source": [
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "# from tensorflow.keras.models import Sequential\n",
        "\n",
        "# num_classes = len(train_data.class_names)\n",
        "\n",
        "# VERSÃO 1\n",
        "# model = Sequential([\n",
        "#   layers.Rescaling(1./255, input_shape=(220, 220, 3)),\n",
        "#   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Flatten(),\n",
        "#   layers.Dense(128, activation='relu'),\n",
        "#   layers.Dense(num_classes)\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_VGzJu18OfA"
      },
      "outputs": [],
      "source": [
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "# from tensorflow.keras.models import Sequential\n",
        "\n",
        "# num_classes = len(train_data.class_names)\n",
        "\n",
        "# # VERSÃO 2\n",
        "# data_augmentation = keras.Sequential(\n",
        "#   [\n",
        "#     layers.RandomFlip(\"horizontal\",\n",
        "#                       input_shape=(220,\n",
        "#                                   220,\n",
        "#                                   3)),\n",
        "#     layers.RandomRotation(0.1),\n",
        "#     layers.RandomZoom(0.1),\n",
        "#   ]\n",
        "# )\n",
        "\n",
        "# model = Sequential([\n",
        "#   data_augmentation,\n",
        "#   layers.Rescaling(1./255),\n",
        "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Dropout(0.2),\n",
        "#   layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Dropout(0.2),\n",
        "#   layers.Flatten(),\n",
        "#   layers.Dense(128, activation='relu'),\n",
        "#   layers.Dense(128, activation='relu'),\n",
        "#   layers.Dense(128, activation='relu'),\n",
        "#   layers.Dense(128, activation='relu'),\n",
        "#   layers.Dense(num_classes, name=\"outputs\", activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "num_classes = len(train_data.class_names)\n",
        "\n",
        "# VERSÃO 3\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(220, 220, 3)),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomBrightness(0.2),\n",
        "  layers.RandomContrast(0.2),\n",
        "  ]\n",
        ")\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(num_classes, name=\"outputs\", activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BkvRhxZKUw7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLf1whtIK4xQ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crubwxd4K6e6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "epochs=14\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",  # Métrica monitorada\n",
        "    patience=3,          # Número de épocas sem melhoria antes de parar\n",
        "    restore_best_weights=True,  # Restaura os pesos do melhor modelo\n",
        "    verbose=1            # Exibe mensagens no console\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "  train_data,\n",
        "  validation_data=val_data,\n",
        "  epochs=epochs,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_label = model.predict(val_data, batch_size=32)"
      ],
      "metadata": {
        "id": "OZOG41fSHVbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_label = np.argmax(predict_label, axis=1)"
      ],
      "metadata": {
        "id": "x27JVU6zLXPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_label, len(predict_label)"
      ],
      "metadata": {
        "id": "NKel-0UcLqGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_label(image, label):\n",
        "  return label\n",
        "\n",
        "labels = val_data.map(extract_label)\n",
        "true_label = [label.numpy() for label in labels]"
      ],
      "metadata": {
        "id": "8GedjIYGIKxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_label = np.argmax(true_label, axis=1)"
      ],
      "metadata": {
        "id": "030B5PKuLvek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_label, len(true_label)"
      ],
      "metadata": {
        "id": "JxvDwgUpMb1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(true_label, predict_label)"
      ],
      "metadata": {
        "id": "6Kq894ivMn-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['Early_Renaissance', 'Fauvism', 'Minimalism', 'Pop_Art', 'Ukiyo_e']\n",
        "\n",
        "print(classification_report(true_label, predict_label, target_names=target_names))"
      ],
      "metadata": {
        "id": "-eFwMWQ8NWh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model.weights.h5\")"
      ],
      "metadata": {
        "id": "ZB9WmHd7LOAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_weights(\"model.weights.h5\")"
      ],
      "metadata": {
        "id": "FcMkIyutx7Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIzlTbUfLC_N"
      },
      "outputs": [],
      "source": [
        "# acc = history.history['accuracy']\n",
        "# val_acc = history.history['val_accuracy']\n",
        "\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "\n",
        "# epochs_range = range(epochs)\n",
        "\n",
        "# plt.figure(figsize=(8, 8))\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "# plt.legend(loc='lower right')\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(epochs_range, loss, label='Training Loss')\n",
        "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "# plt.legend(loc='upper right')\n",
        "# plt.title('Training and Validation Loss')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzqFJqRo8XKh"
      },
      "source": [
        "## [Computer Vision Course - Hugging Face](https://huggingface.co/learn/computer-vision-course/en/unit0/welcome/welcome)\n",
        "\n",
        "### Contextualização e introdução a elementos básicos de Visão Computacional\n",
        "\n",
        "##### Introdução\n",
        "\n",
        "- A visão humana trabalha com a 'entrada' de uma imagem e extração de informações dessa entrada. Visão Computacional é uma tarefa semelhante, mas pode ser muito mais abrangente!\n",
        "- Como é o reconhecimento de bolas usadas em esportes (humanos X computadores)? Essa é uma tarefa que envolve uma análise do contexto geral em que essa bola está inserida, e a classificação exata depende muito do local em que essa bola está inserida, e é aí que entra o uso de Inteligência Artificial!\n",
        "- O uso de programação pura para realizar uma detecção desse tipo é muito difícil, pois o contexto é muito significativo nessa questão (e em várias outras). Em tarefas assim, existe a necessidade de sistemas mais robustos. Por isso Visão Computacional está estreitamente relacionada a IA!\n",
        "\n",
        "##### Imagens\n",
        "\n",
        "- Imagens como funções de N dimensões; pensando em 2 dimensões, cada par de coordenadas xi, yi é um elemento da imagem (pixel, picture element) e a amplitude de F para essa coordenad indica o nível de cinza no ponto. Pensando em cores, cada canal da imagem é uma diferente componente de cor dessa imagem e temos um F pra cada componente de cor (referenciando F(x, y)). Também há outros tipos de imagem em que a função F traz um label para os pixels.\n",
        "- Comumente, os computadores 'visualizam' imagens como matrizes (um array numérico de duas dimensões)!\n",
        "- Vídeos: adicionamos uma terceira dimensão à função F e incluímos a dimensão do tempo (F(x, y, t)).\n",
        "\n",
        "...\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Redes Neurais Convolucionais (Convolutional Neural Networks - CNNs)\n",
        "\n",
        "##### Convolução\n",
        "- Convolução: uma janela com números que atravessa os dados e realiza uma multiplicação e soma desses valores; o resultado desse filtro é a taxa de variação dos dados (derivada!). Essa ideia é a base dos filtros em PDI (filtro de Prewitt, Sobel etc.).\n",
        "\n",
        "##### CNNs\n",
        "- A ideia é utilizar filtros para extrair informações de imagens e, como alguns filtros funcionam melhor ou pior com certas imagens, definir os filtros ótimos que conseguem extrair informações importantes\n",
        "- Muitas vezes, interessa-nos apenas as bordas detectadas em uma imagem. Assim, para 'resumir' uma imagem, realizamos 'pooling' e temos menos parâmetros e ainda assim temos as informações necessárias para trabalhar. Assim, pooling é a operação de obter o elemento de valor mais importante no feature map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmWwp89lj8dq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}